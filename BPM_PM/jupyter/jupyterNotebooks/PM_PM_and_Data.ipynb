{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f60261-9520-4885-8c0d-af041723cc8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0f655ac1-fd08-40d8-8e3f-d0f7ef227624",
   "metadata": {},
   "source": [
    "<center><font size=\"+4\">Programming & Data Analytics & AI 2 PM 2024/2025</font></center>\n",
    "<center><font size=\"+2\">Sant'Anna School of Advanced Studies, Pisa, Italy</font></center>\n",
    "<center><img src=\"https://github.com/EMbeDS-education/ComputingDataAnalysisModeling20242025/raw/main/PDAI/jupyter/jupyterNotebooks/images/sssaLEMBEDSdtu.png\" width=\"900\" alt=\"L'EMbeDS\"></center>\n",
    "\n",
    "<center><font size=\"+2\">Course responsible</font></center>\n",
    "<center><font size=\"+2\">Andrea Vandin a.vandin@santannapisa.it</font></center>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264ae39e-9579-4d33-9487-1510885f4eea",
   "metadata": {},
   "source": [
    "<center><font size=\"+2\">Notebook for Classes 4 and 5 </font></center>\n",
    "<center><font size=\"+2\">PM and Data: case studies, benchmarks, event data vs non event data\n",
    "</font></center>\n",
    "\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b9ccd8-67cd-46d5-80b2-2f16a5a4f2aa",
   "metadata": {},
   "source": [
    "# Can we make non-PM data into PM data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c110f8c4-9423-44e2-9b3c-3262f2b1dbe8",
   "metadata": {},
   "source": [
    "Yes!\n",
    "\n",
    "It is not always the case that we have 'activities', 'case ids', and 'time stamps'.\n",
    "\n",
    "Sometimes we need to make these up ourselves\n",
    "- a sort of feature engineering\n",
    "\n",
    "Many works have transformed, e.g., time series into PM-amenable data\n",
    "- here, we try playing with the stock prices discussed in the class on pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5740d51f-68ab-4b12-9a8b-0999af7cd312",
   "metadata": {},
   "source": [
    "# On datasets for Process mining"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104f65df-bcd2-4787-ae0a-a1268db5ef14",
   "metadata": {},
   "source": [
    "As we have seen, in order to apply PM we need a dataset with\n",
    "- __case ids__: there must entities studied over time\n",
    "- __activities/events__: there must be discrete __activities__ that happen to each entity. Each execution of an activity is an event\n",
    "- __timestamps__: there must be a timestamp associated to each event. Or at least a counter that puts events in the right order\n",
    "\n",
    "What is not mandatory is the presence of a _known process_ behind the data\n",
    "- PM is not just for Management sciences...\n",
    "- Many people use it as a mean to have a different perspective on studied data\n",
    "  - to do reverse engineering on a given system\n",
    "  - to find inconsistencies in a text\n",
    "  - to check if a simulated model does what promised in the corresponding scientific paper ;D\n",
    "  - to do anomaly detection in cybersecurity\n",
    "    - If I learn the behavior of 'normal users' of a system\n",
    "    - I can spot anomalous behavior of 'bad users'\n",
    "  - to do process-oriented classification\n",
    "    - I learn some models/processes.\n",
    "    - Whenever a new trace comes, I assign to it the _closest_ model/ I classify it\n",
    "  - to detect cognitive decline in patients\n",
    "- ...\n",
    "  \n",
    "\n",
    "\n",
    "In all these unusual cases, coming up with case ids, activities and timestamps is difficult and crucial!\n",
    "- As usual in data science, __pre-processing can be the most-consuming task__. \n",
    "\n",
    "The [Process Mining Manifesto](https://www.tf-pm.org/upload/1580737614108.pdf) has a section on this in Chaper 4 Challenges:\n",
    "- Finding, Merging, and Cleaning Event Data:\n",
    "- > _It still takes considerable efforts to extract event data suitable for process mining. Typically, several hurdles need to be overcome..._\n",
    "\n",
    "\n",
    "Overviews on this problem are provided in the following review papers\n",
    "- [Extraction, Correlation, and Abstraction of Event Data for Process Mining](https://www2.informatik.hu-berlin.de/~weidlima/pubs/diba_dmkd_2020_extraction_correlation_abstraction.pdf)\n",
    "  - The journey from raw data to event logs suitable for process mining can be addressed by a variety of methods and techniques. It reviews and classifies techniques in the literature to support the creation of event logs from raw data\n",
    "- [Turning Logs into Lumber: Preprocessing Tasks in Process Mining\n",
    "](https://arxiv.org/abs/2309.17100)\n",
    "  - This paper presents a systematic literature review that establishes a comprehensive repository of preprocessing tasks and their usage in case studies. We identify six high-level and 20 low-level preprocessing tasks in case studies. Log filtering, transformation, and abstraction are commonly used, while log enriching, integration, and reduction are less frequent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367c8df0-ba86-49d1-95e8-3ad6f6df287a",
   "metadata": {},
   "source": [
    "For a discussion on this, I recommend you watching class 2.1 of the Coursera course on PM\n",
    "- https://www.coursera.org/learn/process-mining/lecture/uA8rJ/2-1-event-logs-and-process-models\n",
    "- https://www.coursera.org/learn/process-mining/home/welcome"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba325240-8dc3-4301-9fc3-4f3e52c4461a",
   "metadata": {},
   "source": [
    "# Possible non-PM datasets to transform in PM datasets!?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e27997-1db6-4440-9329-5367d7d2cc65",
   "metadata": {},
   "source": [
    "## Financial transactions?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd5765b-a9ef-4e87-8efd-010eb59ef07e",
   "metadata": {},
   "source": [
    "Kaggle contains a number of datasets on transactions\n",
    "\n",
    "In the previous class we mentioned _transactions_\n",
    "- Datasets on transactions can be easily transformed in event logs!\n",
    "\n",
    "Some available on Kaggle:\n",
    "- https://www.kaggle.com/datasets/vipin20/transaction-data\n",
    "- https://www.kaggle.com/datasets/prasad22/daily-transactions-dataset\n",
    "- https://www.kaggle.com/datasets/apoorvwatsky/bank-transaction-data\n",
    "- https://www.kaggle.com/datasets/priyamchoksi/credit-card-transactions-dataset\n",
    "- https://www.kaggle.com/datasets/computingvictor/transactions-fraud-datasets\n",
    "- https://www.kaggle.com/datasets/kartik2112/fraud-detection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0567298-8401-4a68-ac13-1ee3903c36c5",
   "metadata": {},
   "source": [
    "### For example, https://www.kaggle.com/datasets/vipin20/transaction-data has:\n",
    "\n",
    "- A item purchased transactions data. \n",
    "- It has 8 columns: \n",
    "  - UserId -It is a unique ID for all User Id\n",
    "  - TransactionId -It contains unique Transactions ID\n",
    "  - TransactionTime -It contains Transaction Time\n",
    "  - ItemCode -It contains item code that item will be purchased\n",
    "  - ItemDescription -It contains Item description\n",
    "  - NumberOfItemPurchased -It contains total number of items Purchased\n",
    "  - CostPerltem -Cost per item Purchased\n",
    "  - Country -Country where item purchased\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6cb0a7-43b8-421a-bdd6-71d4c17c38df",
   "metadata": {},
   "source": [
    "Possible PM-mapping:\n",
    "- Case Id -> userid\n",
    "- Timestamp -> TransactionTime\n",
    "- Activity -> it depends on what you want to study: \n",
    "  - ItemCode?\n",
    "  - Price? (NumberOfItemPurchases*CostPerItem)\n",
    "  - Country?\n",
    "  - Synthetize extra info?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e887cb-5219-4bdd-b661-e641706cc020",
   "metadata": {},
   "source": [
    "### https://www.kaggle.com/datasets/priyamchoksi/credit-card-transactions-dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd3da83-6506-47b2-9e04-1231c4c6d207",
   "metadata": {},
   "source": [
    "Actual source:\n",
    "- https://huggingface.co/datasets/pointe77/credit-card-transaction\n",
    "\n",
    "The Credit Card Transactions Dataset provides \n",
    "- detailed records of credit card transactions,\n",
    "- including information about transaction times, amounts, and associated personal and merchant details.\n",
    "- This dataset has over __1.85M rows__.\n",
    "\n",
    "How This Dataset Can Be Used (from the dataset website):\n",
    "\n",
    "- Fraud Detection : Use machine learning models to __identify fraudulent transactions by examining patterns in transaction amounts__, locations, and user profiles. Enhancing fraud detection systems becomes feasible by __analyzing behavioral patterns__.\n",
    "\n",
    "- Customer Segmentation : __Segment customers based on spending patterns__, location, and demographics. Tailor marketing strategies and personalized offers to these different customer segments for better engagement.\n",
    "\n",
    "- Transaction Classification : Classify transactions into categories such as grocery or entertainment to understand spending behaviors. This helps in improving recommendation systems by identifying transaction categories and preferences.\n",
    "\n",
    "- Geospatial Analysis : Analyze transaction data geographically to map spending patterns and detect regional trends or anomalies based on latitude and longitude.\n",
    "\n",
    "- Predictive Modeling : Build models to forecast future spending behavior using historical transaction data. Predict potential fraudulent activities and financial trends.\n",
    "\n",
    "- Behavioral Analysis : Examine how factors like transaction amount, merchant type, and time influence spending behavior. Study the relationships between user demographics and transaction patterns.\n",
    "\n",
    "- Anomaly Detection : Identify __unusual transaction patterns__ that __deviate from normal behavior__ to detect potential fraud early. Employ anomaly detection techniques to spot outliers and suspicious activities.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a334cf-a17b-42c1-a14c-bd543686c047",
   "metadata": {},
   "source": [
    "It contains 24 columns\n",
    "- Case ID: depends on the perspective\n",
    "  - cc_num, (who buys)\n",
    "  - merchant (who sells\n",
    "- Timestamp: trans_date_trans_time\n",
    "- Activity\n",
    "  - buy: it would be too simple. Just one action\n",
    "  - buy_a_given_category: this could be interesting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681341b6-900b-4a6e-8cb4-51732b56f8c1",
   "metadata": {},
   "source": [
    "### https://www.kaggle.com/datasets/apoorvwatsky/bank-transaction-data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8724049c-e4b0-4d8a-b76e-1bcac1ec4563",
   "metadata": {},
   "source": [
    "#### Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c446017b-10cb-4db1-a8cf-2888ac46c3e4",
   "metadata": {},
   "source": [
    "Inspiration:\n",
    "- We want to detect fraud transactions and money laundering.\n",
    "- It is the concealment of the origins of illegally obtained money, typically by means of transfers involving foreign banks or legitimate businesses.\n",
    "\n",
    "Columns:\n",
    "- Account No. - This represents the account number involved in transaction.\n",
    "- Date - Date of transaction\n",
    "- Transaction Details - Transaction narrations in bank statements\n",
    "- Cheque No. - This indicates the cheque number\n",
    "- Value Date - Date of completion of transaction\n",
    "- Withdrawal Amount - Indicates the amount withdrawn\n",
    "- Deposit Amount - Indicates the amount deposited\n",
    "- Balance Amount - Current balance of account"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0661e3-5fb5-4f82-99c5-dacfff1251b9",
   "metadata": {},
   "source": [
    "Possible PM-mapping:\n",
    "- Case Id -> Account no\n",
    "- Timestamp -> Date\n",
    "- Activity -> it depends on what we want to study\n",
    "  - Withdrawal Amount \n",
    "  - Deposit Amount\n",
    "  - Syhntetise extra info?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347ce345-798f-42ea-8d87-a01ca9c021af",
   "metadata": {},
   "source": [
    "> __The dataset is not interesting because it has only 10 bank accounts!__\n",
    "> - That is, only 10 case ids.\n",
    "> - We leave some code nevertheles as examples of computation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39f5bc1-f92b-4d79-bc5e-0106fb737b19",
   "metadata": {},
   "source": [
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1daf59-a2a0-4915-b0d6-88f083113ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f049dd3d-d638-40f6-8709-9ebfe3a3f319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 116201 entries, 0 to 116200\n",
      "Data columns (total 9 columns):\n",
      " #   Column               Non-Null Count   Dtype         \n",
      "---  ------               --------------   -----         \n",
      " 0   Account No           116201 non-null  object        \n",
      " 1   DATE                 116201 non-null  datetime64[ns]\n",
      " 2   TRANSACTION DETAILS  113702 non-null  object        \n",
      " 3   CHQ.NO.              905 non-null     float64       \n",
      " 4   VALUE DATE           116201 non-null  datetime64[ns]\n",
      " 5   WITHDRAWAL AMT       53549 non-null   float64       \n",
      " 6   DEPOSIT AMT          62652 non-null   float64       \n",
      " 7   BALANCE AMT          116201 non-null  float64       \n",
      " 8   .                    116201 non-null  object        \n",
      "dtypes: datetime64[ns](2), float64(4), object(3)\n",
      "memory usage: 8.0+ MB\n"
     ]
    }
   ],
   "source": [
    "bank=pd.read_excel('bank.xlsx')\n",
    "bank.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "596c32a9-9eac-4cc8-8e2a-d962f32a7c19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Account No</th>\n",
       "      <th>DATE</th>\n",
       "      <th>TRANSACTION DETAILS</th>\n",
       "      <th>CHQ.NO.</th>\n",
       "      <th>VALUE DATE</th>\n",
       "      <th>WITHDRAWAL AMT</th>\n",
       "      <th>DEPOSIT AMT</th>\n",
       "      <th>BALANCE AMT</th>\n",
       "      <th>.</th>\n",
       "      <th>deposit</th>\n",
       "      <th>activity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>409000611074'</td>\n",
       "      <td>2017-06-29</td>\n",
       "      <td>TRF FROM  Indiaforensic SERVICES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-06-29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>1.000000e+06</td>\n",
       "      <td>.</td>\n",
       "      <td>True</td>\n",
       "      <td>Deposit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>409000611074'</td>\n",
       "      <td>2017-07-05</td>\n",
       "      <td>TRF FROM  Indiaforensic SERVICES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-07-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>2.000000e+06</td>\n",
       "      <td>.</td>\n",
       "      <td>True</td>\n",
       "      <td>Deposit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>409000611074'</td>\n",
       "      <td>2017-07-18</td>\n",
       "      <td>FDRL/INTERNAL FUND TRANSFE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-07-18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>500000.0</td>\n",
       "      <td>2.500000e+06</td>\n",
       "      <td>.</td>\n",
       "      <td>True</td>\n",
       "      <td>Deposit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>409000611074'</td>\n",
       "      <td>2017-08-01</td>\n",
       "      <td>TRF FRM  Indiaforensic SERVICES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-08-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3000000.0</td>\n",
       "      <td>5.500000e+06</td>\n",
       "      <td>.</td>\n",
       "      <td>True</td>\n",
       "      <td>Deposit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>409000611074'</td>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>FDRL/INTERNAL FUND TRANSFE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>500000.0</td>\n",
       "      <td>6.000000e+06</td>\n",
       "      <td>.</td>\n",
       "      <td>True</td>\n",
       "      <td>Deposit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116196</th>\n",
       "      <td>409000362497'</td>\n",
       "      <td>2019-03-05</td>\n",
       "      <td>TRF TO 1196428  Indiaforensic SE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-03-05</td>\n",
       "      <td>117934.30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.901902e+09</td>\n",
       "      <td>.</td>\n",
       "      <td>False</td>\n",
       "      <td>Withdrawal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116197</th>\n",
       "      <td>409000362497'</td>\n",
       "      <td>2019-03-05</td>\n",
       "      <td>FDRL/INTERNAL FUND TRANSFE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-03-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>300000.0</td>\n",
       "      <td>-1.901602e+09</td>\n",
       "      <td>.</td>\n",
       "      <td>True</td>\n",
       "      <td>Deposit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116198</th>\n",
       "      <td>409000362497'</td>\n",
       "      <td>2019-03-05</td>\n",
       "      <td>FDRL/INTERNAL FUND TRANSFE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-03-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>300000.0</td>\n",
       "      <td>-1.901302e+09</td>\n",
       "      <td>.</td>\n",
       "      <td>True</td>\n",
       "      <td>Deposit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116199</th>\n",
       "      <td>409000362497'</td>\n",
       "      <td>2019-03-05</td>\n",
       "      <td>IMPS 05-03-20194C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-03-05</td>\n",
       "      <td>109868.65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.901412e+09</td>\n",
       "      <td>.</td>\n",
       "      <td>False</td>\n",
       "      <td>Withdrawal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116200</th>\n",
       "      <td>409000362497'</td>\n",
       "      <td>2019-03-05</td>\n",
       "      <td>Sweep Trf To: 40900036427</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-03-05</td>\n",
       "      <td>5000.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.901417e+09</td>\n",
       "      <td>.</td>\n",
       "      <td>False</td>\n",
       "      <td>Withdrawal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>116201 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Account No       DATE               TRANSACTION DETAILS  CHQ.NO.  \\\n",
       "0       409000611074' 2017-06-29  TRF FROM  Indiaforensic SERVICES      NaN   \n",
       "1       409000611074' 2017-07-05  TRF FROM  Indiaforensic SERVICES      NaN   \n",
       "2       409000611074' 2017-07-18        FDRL/INTERNAL FUND TRANSFE      NaN   \n",
       "3       409000611074' 2017-08-01   TRF FRM  Indiaforensic SERVICES      NaN   \n",
       "4       409000611074' 2017-08-16        FDRL/INTERNAL FUND TRANSFE      NaN   \n",
       "...               ...        ...                               ...      ...   \n",
       "116196  409000362497' 2019-03-05  TRF TO 1196428  Indiaforensic SE      NaN   \n",
       "116197  409000362497' 2019-03-05        FDRL/INTERNAL FUND TRANSFE      NaN   \n",
       "116198  409000362497' 2019-03-05        FDRL/INTERNAL FUND TRANSFE      NaN   \n",
       "116199  409000362497' 2019-03-05                 IMPS 05-03-20194C      NaN   \n",
       "116200  409000362497' 2019-03-05         Sweep Trf To: 40900036427      NaN   \n",
       "\n",
       "       VALUE DATE  WITHDRAWAL AMT  DEPOSIT AMT   BALANCE AMT  .  deposit  \\\n",
       "0      2017-06-29             NaN    1000000.0  1.000000e+06  .     True   \n",
       "1      2017-07-05             NaN    1000000.0  2.000000e+06  .     True   \n",
       "2      2017-07-18             NaN     500000.0  2.500000e+06  .     True   \n",
       "3      2017-08-01             NaN    3000000.0  5.500000e+06  .     True   \n",
       "4      2017-08-16             NaN     500000.0  6.000000e+06  .     True   \n",
       "...           ...             ...          ...           ... ..      ...   \n",
       "116196 2019-03-05       117934.30          NaN -1.901902e+09  .    False   \n",
       "116197 2019-03-05             NaN     300000.0 -1.901602e+09  .     True   \n",
       "116198 2019-03-05             NaN     300000.0 -1.901302e+09  .     True   \n",
       "116199 2019-03-05       109868.65          NaN -1.901412e+09  .    False   \n",
       "116200 2019-03-05         5000.00          NaN -1.901417e+09  .    False   \n",
       "\n",
       "          activity  \n",
       "0          Deposit  \n",
       "1          Deposit  \n",
       "2          Deposit  \n",
       "3          Deposit  \n",
       "4          Deposit  \n",
       "...            ...  \n",
       "116196  Withdrawal  \n",
       "116197     Deposit  \n",
       "116198     Deposit  \n",
       "116199  Withdrawal  \n",
       "116200  Withdrawal  \n",
       "\n",
       "[116201 rows x 11 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mark as withdrawal or deposit\n",
    "bank['deposit'] = bank['DEPOSIT AMT'].notnull()\n",
    "bank['activity']=bank[['deposit']].applymap(lambda x: 'Deposit' if x else 'Withdrawal')\n",
    "\n",
    "bank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "65ac8ad0-b0d1-4e83-93ce-89ad19b6a3d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         1000000.00\n",
       "1         1000000.00\n",
       "2          500000.00\n",
       "3         3000000.00\n",
       "4          500000.00\n",
       "             ...    \n",
       "116196    -117934.30\n",
       "116197     300000.00\n",
       "116198     300000.00\n",
       "116199    -109868.65\n",
       "116200      -5000.00\n",
       "Name: amount, Length: 116201, dtype: float64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bank['amount']= bank['DEPOSIT AMT'].sub(bank['WITHDRAWAL AMT'],fill_value=0)\n",
    "bank['amount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a749fc2e-24ab-4f41-a519-278a7dc85833",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Account No', 'DATE', 'TRANSACTION DETAILS', 'CHQ.NO.', 'VALUE DATE',\n",
      "       'WITHDRAWAL AMT', 'DEPOSIT AMT', 'BALANCE AMT', '.', 'deposit',\n",
      "       'activity', 'amount'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(bank.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5f15c16c-3d7c-4cef-9538-7be87b1a2058",
   "metadata": {},
   "outputs": [],
   "source": [
    "bank['TRANSACTION DETAILS'].fillna(value=\"no details\",inplace=True)\n",
    "bank['DATE']=pd.to_datetime(bank['DATE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f455b179-600c-42c3-9efa-c95627154042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 116201 entries, 0 to 116200\n",
      "Data columns (total 6 columns):\n",
      " #   Column               Non-Null Count   Dtype         \n",
      "---  ------               --------------   -----         \n",
      " 0   Account No           116201 non-null  object        \n",
      " 1   DATE                 116201 non-null  datetime64[ns]\n",
      " 2   activity             116201 non-null  object        \n",
      " 3   amount               116201 non-null  float64       \n",
      " 4   TRANSACTION DETAILS  116201 non-null  object        \n",
      " 5   BALANCE AMT          116201 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(2), object(3)\n",
      "memory usage: 5.3+ MB\n"
     ]
    }
   ],
   "source": [
    "event_log=bank[['Account No','DATE','activity','amount','TRANSACTION DETAILS','BALANCE AMT']].copy()\n",
    "event_log.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "cde9500b-d2e2-4b3e-9e30-f1f52f97e3d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['TRF FROM  Indiaforensic SERVICES', 'FDRL/INTERNAL FUND TRANSFE',\n",
       "       'TRF FRM  Indiaforensic SERVICES', ..., 'NEFT/000069179261/INDIAN',\n",
       "       'NEFT/000069179347/INDIAN', 'IMPS 05-03-20194C'], dtype=object)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_log['TRANSACTION DETAILS'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "96ccf36d-d88f-41b5-b33f-5945babf4fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have\n",
      "\t 10 cases (orders)\n",
      "\t 116201 events (rows in the csv), over\n",
      "\t 2 activities (the \"things\" that can happen in an event)\n"
     ]
    }
   ],
   "source": [
    "n_cases=len(event_log['Account No'].unique())\n",
    "n_events=len(event_log)\n",
    "n_activities=len(event_log.activity.unique())\n",
    "print('We have\\n\\t',n_cases,'cases (orders)\\n\\t', n_events,'events (rows in the csv), over\\n\\t',n_activities,'activities (the \"things\" that can happen in an event)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55dd22e4-2c60-43fb-bcca-d9d99ec4a631",
   "metadata": {},
   "source": [
    "> If interested in continuing the PM analysis, one could synthetize new actions starting from the basic deposit/withdraw\n",
    "> - how much (little , medium, a lot)\n",
    "> - what (using tranaction details)\n",
    "> - information on status (balance AMT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e25d76d-15ea-429b-9527-e3bfb17ad8d4",
   "metadata": {},
   "source": [
    "Let's put some pm4py into the scene\n",
    "- We format the dataframe to enable PM techniques\n",
    "- We extract start and end activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f723d50-e745-4edf-a77c-5416cad34ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_log = pm4py.format_dataframe(event_log, case_id='Account No', activity_key='activity', timestamp_key='DATE')\n",
    "start_activities = pm4py.get_start_activities(event_log)\n",
    "end_activities = pm4py.get_end_activities(event_log)\n",
    "print(\"Start activities: {}\\nEnd activities: {}\\n\".format(start_activities, end_activities))\n",
    "\n",
    "#print('The case_id 2 in the formatted dataframe')\n",
    "#event_log[event_log.case_id==2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74036670-199f-422e-baee-7fc917d5835b",
   "metadata": {},
   "source": [
    "## Logs from simulations of (economic) agent-based models!?\n",
    "\n",
    "- In some domains, we create very complex models that can be analyzed only by means of simulations\n",
    "- Each simulation does many things, executes many _events_\n",
    "- Can we create logs using _interesting events_?\n",
    "- Can these logs be used to _explain the models_?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4d8e25-1e71-43f6-b743-91b35dc81b6b",
   "metadata": {},
   "source": [
    "I am working on this since some time\n",
    "- https://www.sciencedirect.com/science/article/pii/S0164121224000268?via%3Dihub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cbc68e1-45ca-4370-af0d-a6717a2509e4",
   "metadata": {},
   "source": [
    "I considered _simple models_ \n",
    "- Now, Ernest is planning to _do this for real_ on complex models! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e548e16a-70cb-4121-b6cb-f2a71e386ebb",
   "metadata": {},
   "source": [
    "# Case studies\n",
    "\n",
    "## Case studies\n",
    "A selection of case studies by the IEEE Task Force in Process Mining\n",
    "- https://www.tf-pm.org/resources/casestudy\n",
    "\n",
    "## Process miner of the year: \n",
    "A selection of Disco-related studies collected by Disco's company\n",
    "   - https://fluxicon.com/pmoty/2016/\n",
    "   - https://fluxicon.com/pmoty/2017/\n",
    "   - https://fluxicon.com/pmoty/2018/\n",
    "   - https://fluxicon.com/pmoty/2019/\n",
    "   - https://fluxicon.com/pmoty/2020/\n",
    "   - https://fluxicon.com/pmoty/2021/\n",
    "   - https://fluxicon.com/pmoty/2022/\n",
    "   - https://fluxicon.com/pmoty/2023/\n",
    "   - https://fluxicon.com/pmoty/2024/\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df622ab-6c18-43ea-822e-82663395fe5c",
   "metadata": {},
   "source": [
    "# Some famous PM datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7c2705-9095-49b9-8686-3537c072b748",
   "metadata": {},
   "source": [
    "## A webpage collecting many PM datasets (some are provided below as well)\n",
    "- https://www.processmining.org/event-data.html\n",
    "\n",
    "Available data sets in XES or CSV:\n",
    "- Hospital Billing - Event Log\n",
    "- Sepsis Cases - Event Log\n",
    "- Road Traffic Fine Management Process\n",
    "- BPIC 2020 (BPI Challenge 2020)\n",
    "- Purchase order handling process (BPI Challenge 2019)\n",
    "- Payment process of Common Agricultural Policy (BPI Challenge 2018)\n",
    "- Loan application process of a Dutch financial institute (BPI Challenge 2017)\n",
    "- Municipality log 1 (BPI Challenge 2015)\n",
    "- Municipality log 2 (BPI Challenge 2015)\n",
    "- Municipality log 3 (BPI Challenge 2015)\n",
    "- Municipality log 4 (BPI Challenge 2015)\n",
    "- Municipality log 5 (BPI Challenge 2015)\n",
    "- Incident management log (BPI Challenge 2013)\n",
    "- Problem management log, open problems (BPI Challenge 2013)\n",
    "- Problem management log, closed problems (BPI Challenge 2013)\n",
    "- Event log of a loan application process (BPI Challenge 2012)\n",
    "- Anonymized event log of a Dutch Academic Hospital (BPI Challenge 2011)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc68341-cb96-486a-b4ca-bfdf6f156645",
   "metadata": {},
   "source": [
    "## Another webpage collecting many PM datasets (most of which are also in the link above)\n",
    "\n",
    "https://www.tf-pm.org/resources/logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0e5a88-f917-4baf-ba8e-82738ce7fd1f",
   "metadata": {},
   "source": [
    "List of event logs for process mining purposes. In the link you can use the menu on the right to filter only the logs you are interested into.\n",
    "\n",
    "\n",
    "- Process Discovery Contest 2024artificial event logs pdc 2024 pnml process discovery contest xes\n",
    "23 Sep 2024\n",
    "- Process Discovery Contest 2023artificial event logs pdc 2023 pnml process discovery contest xes\n",
    "4 Oct 2023 (update: 4 Oct 2023)\n",
    "- Process Discovery Contest 2022artificial event logs pdc 2022 pnml process discovery contest xes\n",
    "3 Oct 2022 (update: 10 Feb 2025)\n",
    "- Process Discovery Contest 2021artificial event logs pdc 2021 pnml process discovery contest xes\n",
    "19 Oct 2021 (update: 31 Oct 2022)\n",
    "- Process Discovery Contest 2020artificial event logs pdc 2020 pnml process discovery contest xes\n",
    "21 May 2021 (update: 31 Oct 2022)\n",
    "- Process Discovery Contest 2019artificial event logs pdc 2019 process discovery contest xes\n",
    "21 May 2021 (update: 10 May 2023)\n",
    "- Process Discovery Contest 2017artificial event logs pdc 2017 process discovery contest xes\n",
    "21 May 2021 (update: 31 Oct 2022)\n",
    "- Process Discovery Contest 2016artificial event logs pdc 2016 process discovery contest xes\n",
    "21 May 2021 (update: 31 Oct 2022)\n",
    "- Purchase order handling process (BPI Challenge 2019)bpi-challenge csv purchase orders xes\n",
    "20 Dec 2019\n",
    "- Payment process of Common Agricultural Policy (BPI Challenge 2018)bpi-challenge payment xes\n",
    "20 Dec 2019 (update: 28 Jun 2023)\n",
    "- Loan application process of a Dutch financial institute (BPI Challenge 2017)bpi-challenge loan-application xes\n",
    "20 Dec 2019 (update: 28 Jun 2023)\n",
    "- Click-data for the customers that are not logged in to the website (BPI Challenge 2016)bpi-challenge csv customers\n",
    "20 Dec 2019 (update: 28 Jun 2023)\n",
    "- Click-data for the customers that are logged in to the website (BPI Challenge 2016)bpi-challenge csv customers\n",
    "20 Dec 2019 (update: 28 Jun 2023)\n",
    "- Questions asked by customers (BPI Challenge 2016)bpi-challenge csv customers\n",
    "20 Dec 2019 (update: 28 Jun 2023)\n",
    "- Messages sent by customers (BPI Challenge 2016)bpi-challenge csv customers\n",
    "20 Dec 2019 (update: 28 Jun 2023)\n",
    "- Complaints filed by customers (BPI Challenge 2016)bpi-challenge csv customers\n",
    "20 Dec 2019 (update: 28 Jun 2023)\n",
    "- Municipality log 1 (BPI Challenge 2015)bpi-challenge municipalities xes\n",
    "20 Dec 2019 (update: 28 Jun 2023)\n",
    "- Municipality log 2 (BPI Challenge 2015)bpi-challenge municipalities xes\n",
    "20 Dec 2019 (update: 28 Jun 2023)\n",
    "- Municipality log 3 (BPI Challenge 2015)bpi-challenge municipalities xes\n",
    "20 Dec 2019 (update: 28 Jun 2023)\n",
    "- Municipality log 4 (BPI Challenge 2015)bpi-challenge municipalities xes\n",
    "20 Dec 2019 (update: 28 Jun 2023)\n",
    "- Municipality log 5 (BPI Challenge 2015)bpi-challenge municipalities xes\n",
    "20 Dec 2019 (update: 28 Jun 2023)\n",
    "- Change log (BPI Challenge 2014)bpi-challenge csv management\n",
    "20 Dec 2019 (update: 28 Jun 2023)\n",
    "- Incident log (BPI Challenge 2014)bpi-challenge csv management\n",
    "20 Dec 2019 (update: 28 Jun 2023)\n",
    "- Interaction log (BPI Challenge 2014)bpi-challenge csv management\n",
    "20 Dec 2019 (update: 28 Jun 2023)\n",
    "- Incident activity log (BPI Challenge 2014)bpi-challenge csv management\n",
    "20 Dec 2019 (update: 28 Jun 2023)\n",
    "- Incident management log (BPI Challenge 2013)bpi-challenge csv management xes\n",
    "20 Dec 2019 (update: 28 Jun 2023)\n",
    "- Problem management log, open problems (BPI Challenge 2013)bpi-challenge csv management xes\n",
    "20 Dec 2019 (update: 28 Jun 2023)\n",
    "- Problem management log, closed problems (BPI Challenge 2013)bpi-challenge csv management xes\n",
    "20 Dec 2019 (update: 28 Jun 2023)\n",
    "- Event log of a loan application process (BPI Challenge 2012)bpi-challenge loan-application mxml xes\n",
    "20 Dec 2019 (update: 28 Jun 2023)\n",
    "- Anonymized event log of a Dutch Academic Hospital (BPI Challenge 2011)bpi-challenge csv hospital mxml xes\n",
    "20 Dec 2019 (update: 28 Jun 2023)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8cf7ff-63a1-4e5d-a635-4ed4ce4ff5cb",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "390b81c8-6080-4949-b50d-37fc2dc649ce",
   "metadata": {},
   "source": [
    "## Some more details on the provided datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cbea7ab-26b7-442c-a021-c4e7c5c23a89",
   "metadata": {},
   "source": [
    "### Sepsis\n",
    "- https://data.4tu.nl/articles/dataset/Sepsis_Cases_-_Event_Log/12707639\n",
    "\n",
    "This real-life event log contains events of sepsis cases from a hospital. Sepsis is a life threatening condition typically caused by an infection. One case represents the pathway through the hospital. The events were recorded by the ERP (Enterprise Resource Planning) system of the hospital. There are about 1000 cases with in total 15,000 events that were recorded for 16 different activities. Moreover, 39 data attributes are recorded, e.g., the group responsible for the activity, the results of tests and information from checklists. Events and attribute values have been anonymized. The time stamps of events have been randomized, but the time between events within a trace has not been altered."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fbe1bdd-e4e1-482b-adb5-146cde37855c",
   "metadata": {},
   "source": [
    "### Italian road traffic fines\n",
    "- https://data.4tu.nl/articles/dataset/Road_Traffic_Fine_Management_Process/12683249\n",
    "- https://link.springer.com/article/10.1007/s00607-015-0441-1\n",
    "\n",
    "Real-life event log of an information system managing road traffic fines.\n",
    "- The authors considered a real-life event log and a process model, both of which are provided by the local police of an Italian city. The log contains information about more than 140,000 road-traffic fines. Events relate to notifications, payments, and appeals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2d5fb2-90d1-4298-a0f0-c0fef823fa91",
   "metadata": {},
   "source": [
    "### Building permit applications \n",
    "- https://data.4tu.nl/collections/BPI_Challenge_2015/5065424\n",
    "\n",
    "This data is provided by five Dutch municipalities. The data contains all building permit applications over a period of approximately four years. There are many different activities present, denoted by both codes (attribute concept:name) and labels, both in Dutch (attribute taskNameNL) and in English (attribute taskNameEN). The cases in the log contain information on the main application as well as objection procedures in various stages. Furthermore, information is available about the resource that carried out the task and on the cost of the application (attribute SUMleges). The processes in the five municipalities should be identical, but may differ slightly. Especially when changes are made to procedures, rules or regulations the time at which these changes are pushed into the five municipalities may differ. Of course, __over the four year period, the underlying processes have changed__. The municipalities have a number of questions, namely: \n",
    "- What are the roles of the people involved in the various stages of the process and how do these roles differ across municipalities? \n",
    "- What are the possible points for improvement on the organizational structure for each of the municipalities? \n",
    "- The employees of two of the five municipalities have physically moved into the same location recently. Did this lead to a change in the processes and if so, what is different?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59a6daf-d32d-4225-aa92-9ef10a7a5ee6",
   "metadata": {},
   "source": [
    "### Logs of Volvo IT incident and problem management\n",
    "- https://data.4tu.nl/collections/BPI_Challenge_2013/5065448/1\n",
    "- Logs of Volvo IT incident and problem management\n",
    "\n",
    "Related:\n",
    "- https://data.4tu.nl/articles/dataset/BPI_Challenge_2013_incidents/12693914\n",
    "- Log of Volvo IT incident management system Parent item: BPI Challenge 2013 Logs of Volvo IT incident and problem management"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b102f5-cfb5-4568-bcf6-0e07b40573d3",
   "metadata": {},
   "source": [
    "### Benchmarks from the _BPI challenges_\n",
    "- https://www.tf-pm.org/newsletter/newsletter-stream-2-05-2020/bpi-challenges-10-years-of-real-life-datasets\n",
    "- https://www.tf-pm.org/competitions-awards/bpi-challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00de8c17-a082-408f-9439-89cf8e556922",
   "metadata": {},
   "source": [
    "### BPI Challenge 2020\n",
    "- https://data.4tu.nl/collections/BPI_Challenge_2020/5065541/1\n",
    "- The dataset contains events pertaining to two years of travel expense claims. In 2017, events were collected for two departments, in 2018 for the entire university. The various permits and declaration documents (domestic and international declarations, pre-paid travel costs and requests for payment) all follow a similar process flow. After submission by the employee, the request is sent for approval to the travel administration. If approved, the request is then forwarded to the budget owner and after that to the supervisor. If the budget owner and supervisor are the same person, then only one of these steps is taken. In some cases, the director also needs to approve the request.The process finished with either the trip taking place or a payment being requested and payed. On a high level, we distinguish two types of trips, namely domestic and international. For domestic trips, no prior permission is needed, i.e. an employee can undertake these trips and ask for reimbursement of the costs afterwards. For international trips, permission is needed from the supervisor. This permission is obtained by filing a travel-permit and this travel permit should be approved before making any arrangements. To get the costs for a travel reimbursed, a claim is filed. This can be done as soon as costs are actually payed (for example for flights or conference registration fees), or within two months after the trip (for example hotel and food costs which are usually payed on the spot).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91247bb-701f-4279-b67f-52a34e29cb0d",
   "metadata": {},
   "source": [
    "### A lot of benchmarks from a replicability package\n",
    "\n",
    "- https://zenodo.org/records/7578655\n",
    "- This is the replicability package from paper \"Modelling Data-Aware Stochastic Processes - Discovery and Conformance Checking\"\n",
    "- It contains a number of well-known datasets in the PM literature"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_research",
   "language": "python",
   "name": "env_research"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
